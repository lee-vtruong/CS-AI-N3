{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup & Imports\n",
        "\n",
        "This cell sets up the Python environment and imports all Swarm Intelligence algorithms for parameter sensitivity testing on discrete problems.\n",
        "\n",
        "- Adds the parent directory to Python path\n",
        "- Imports essential libraries: numpy, matplotlib, time\n",
        "- Configures matplotlib for inline display\n",
        "- Imports all Swarm Intelligence algorithms (PSO, ABC, FA, CS, ACO) discrete versions and Knapsack problem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add parent directory to Python path\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "# Import essential libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# Configure matplotlib for inline display in notebook\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "\n",
        "# Import all Swarm Intelligence algorithms (discrete versions)\n",
        "from algorithms import pso, abc, fa, cs, aco\n",
        "from problems.knapsack import generate_knapsack_data, knapsack_fitness\n",
        "\n",
        "print(\"‚úì Imports successful!\")\n",
        "print(f\"‚úì Module path added: {module_path}\")\n",
        "print(\"‚úì All Swarm Intelligence algorithms imported (PSO, ABC, FA, CS, ACO) - Discrete versions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Common Parameters\n",
        "\n",
        "Define common parameters used for all algorithms in parameter sensitivity testing.\n",
        "\n",
        "- N_ITEMS: Number of items in the Knapsack problem\n",
        "- N_RUNS: Number of runs for statistical reliability\n",
        "- POP_SIZE: Population size\n",
        "- MAX_ITER: Maximum number of iterations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Common parameters for all algorithms\n",
        "N_ITEMS = 50  # Number of items in Knapsack problem\n",
        "N_RUNS = 5  # Number of runs (set to 1 for fastest testing, higher for more reliable results)\n",
        "POP_SIZE = 50  # Population size\n",
        "MAX_ITER = 50  # Maximum number of iterations\n",
        "\n",
        "# Generate Knapsack problem instance\n",
        "weights, values, capacity, _ = generate_knapsack_data(N_ITEMS, seed=42)\n",
        "context = {\n",
        "    'weights': weights,\n",
        "    'values': values,\n",
        "    'capacity': capacity\n",
        "}\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"COMMON PARAMETERS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Number of items: {N_ITEMS}\")\n",
        "print(f\"Number of runs: {N_RUNS}\")\n",
        "print(f\"Population size: {POP_SIZE}\")\n",
        "print(f\"Max iterations: {MAX_ITER}\")\n",
        "print(f\"Knapsack capacity: {capacity}\")\n",
        "print(f\"Total weight: {np.sum(weights)}, Total value: {np.sum(values)}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Algorithm Configurations\n",
        "\n",
        "Define parameter configurations for each Swarm Intelligence algorithm (discrete versions).\n",
        "\n",
        "**Instructions:**\n",
        "1. Uncomment the section for the algorithm you want to test\n",
        "2. Comment out all other algorithm sections\n",
        "3. Each config contains algorithm-specific parameters and a descriptive label\n",
        "4. Run the next cell to execute parameter sensitivity tests\n",
        "\n",
        "**Available algorithms:**\n",
        "- PSO: Parameters w, c1, c2\n",
        "- ABC: Parameter limit\n",
        "- FA: Parameters alpha, beta0, gamma\n",
        "- CS: Parameters pa, beta\n",
        "- ACO: Parameters alpha, beta, rho, Q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ALGORITHM CONFIGURATIONS (DISCRETE VERSIONS)\n",
        "# ============================================================================\n",
        "# Uncomment ONE section below to test that algorithm's parameter sensitivity\n",
        "# Comment out all other sections\n",
        "# ============================================================================\n",
        "\n",
        "# ===== PSO PARAMETER SENSITIVITY TEST =====\n",
        "# Uncomment the section below to test PSO (discrete)\n",
        "\n",
        "CONFIGS = [\n",
        "    {'w': 0.5, 'c1': 1.5, 'c2': 1.5, 'label': 'PSO: w=0.5, c1=1.5, c2=1.5'},\n",
        "    {'w': 0.7, 'c1': 2.0, 'c2': 2.0, 'label': 'PSO: w=0.7, c1=2.0, c2=2.0'},\n",
        "    {'w': 0.8, 'c1': 2.0, 'c2': 2.0, 'label': 'PSO: w=0.8, c1=2.0, c2=2.0'},\n",
        "    {'w': 0.9, 'c1': 2.5, 'c2': 2.5, 'label': 'PSO: w=0.9, c1=2.5, c2=2.5'},\n",
        "]\n",
        "ALGORITHM_FUNC = pso.pso_discrete\n",
        "ALGORITHM_NAME = 'PSO'\n",
        "\n",
        "# ===== ABC PARAMETER SENSITIVITY TEST =====\n",
        "# Uncomment the section below to test ABC (discrete)\n",
        "\n",
        "# CONFIGS = [\n",
        "#     {'limit': 5, 'label': 'ABC: limit=5'},\n",
        "#     {'limit': 10, 'label': 'ABC: limit=10'},\n",
        "#     {'limit': 20, 'label': 'ABC: limit=20'},\n",
        "#     {'limit': 50, 'label': 'ABC: limit=50'},\n",
        "# ]\n",
        "# ALGORITHM_FUNC = abc.abc_discrete\n",
        "# ALGORITHM_NAME = 'ABC'\n",
        "\n",
        "# ===== FA PARAMETER SENSITIVITY TEST =====\n",
        "# Uncomment the section below to test FA (discrete)\n",
        "\n",
        "# CONFIGS = [\n",
        "#     {'alpha': 0.2, 'beta0': 1.0, 'gamma': 0.95, 'label': 'FA: Œ±=0.2, Œ≤‚ÇÄ=1.0, Œ≥=0.95'},\n",
        "#     {'alpha': 0.5, 'beta0': 1.0, 'gamma': 0.95, 'label': 'FA: Œ±=0.5, Œ≤‚ÇÄ=1.0, Œ≥=0.95'},\n",
        "#     {'alpha': 0.8, 'beta0': 1.0, 'gamma': 0.95, 'label': 'FA: Œ±=0.8, Œ≤‚ÇÄ=1.0, Œ≥=0.95'},\n",
        "#     {'alpha': 0.5, 'beta0': 0.5, 'gamma': 0.95, 'label': 'FA: Œ±=0.5, Œ≤‚ÇÄ=0.5, Œ≥=0.95'},\n",
        "#     {'alpha': 0.5, 'beta0': 2.0, 'gamma': 0.95, 'label': 'FA: Œ±=0.5, Œ≤‚ÇÄ=2.0, Œ≥=0.95'},\n",
        "#     {'alpha': 0.5, 'beta0': 1.0, 'gamma': 0.5, 'label': 'FA: Œ±=0.5, Œ≤‚ÇÄ=1.0, Œ≥=0.5'},\n",
        "#     {'alpha': 0.5, 'beta0': 1.0, 'gamma': 1.5, 'label': 'FA: Œ±=0.5, Œ≤‚ÇÄ=1.0, Œ≥=1.5'},\n",
        "# ]\n",
        "# ALGORITHM_FUNC = fa.firefly_discrete\n",
        "# ALGORITHM_NAME = 'FA'\n",
        "\n",
        "# ===== CS PARAMETER SENSITIVITY TEST =====\n",
        "# Uncomment the section below to test CS (discrete)\n",
        "\n",
        "# CONFIGS = [\n",
        "#     {'pa': 0.1, 'beta': 1.0, 'label': 'CS: pa=0.1, Œ≤=1.0'},\n",
        "#     {'pa': 0.25, 'beta': 1.5, 'label': 'CS: pa=0.25, Œ≤=1.5'},\n",
        "#     {'pa': 0.5, 'beta': 1.5, 'label': 'CS: pa=0.5, Œ≤=1.5'},\n",
        "#     {'pa': 0.25, 'beta': 1.0, 'label': 'CS: pa=0.25, Œ≤=1.0'},\n",
        "# ]\n",
        "# ALGORITHM_FUNC = cs.cuckoo_search_discrete\n",
        "# ALGORITHM_NAME = 'CS'\n",
        "\n",
        "# ===== ACO PARAMETER SENSITIVITY TEST =====\n",
        "# Uncomment the section below to test ACO (discrete version)\n",
        "\n",
        "# CONFIGS = [\n",
        "#     {'alpha': 0.5, 'beta': 1.0, 'rho': 0.3, 'Q': 1.0, 'label': 'ACO: Œ±=0.5, Œ≤=1.0, œÅ=0.3, Q=1.0'},\n",
        "#     {'alpha': 1.0, 'beta': 2.0, 'rho': 0.5, 'Q': 1.0, 'label': 'ACO: Œ±=1.0, Œ≤=2.0, œÅ=0.5, Q=1.0'},\n",
        "#     {'alpha': 1.5, 'beta': 2.0, 'rho': 0.5, 'Q': 1.0, 'label': 'ACO: Œ±=1.5, Œ≤=2.0, œÅ=0.5, Q=1.0'},\n",
        "#     {'alpha': 1.0, 'beta': 1.0, 'rho': 0.5, 'Q': 1.0, 'label': 'ACO: Œ±=1.0, Œ≤=1.0, œÅ=0.5, Q=1.0'},\n",
        "# ]\n",
        "# ALGORITHM_FUNC = aco.aco_discrete\n",
        "# ALGORITHM_NAME = 'ACO'\n",
        "\n",
        "# ============================================================================\n",
        "# IMPORTANT: Make sure to uncomment ONE algorithm section above\n",
        "# and define CONFIGS and ALGORITHM_FUNC variables\n",
        "# ============================================================================\n",
        "\n",
        "# Check if configuration is set\n",
        "try:\n",
        "    CONFIGS\n",
        "    ALGORITHM_FUNC\n",
        "    ALGORITHM_NAME\n",
        "    print(f\"‚úì Configuration loaded: {ALGORITHM_NAME}\")\n",
        "    print(f\"‚úì Number of configs: {len(CONFIGS)}\")\n",
        "except NameError:\n",
        "    print(\"‚ö† WARNING: No algorithm configuration selected!\")\n",
        "    print(\"Please uncomment ONE algorithm section above and run this cell again.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run Parameter Sensitivity Tests\n",
        "\n",
        "Execute parameter sensitivity tests for all configurations on the Knapsack problem.\n",
        "\n",
        "- Runs each configuration N_RUNS times for statistical reliability\n",
        "- Computes average convergence history for each configuration\n",
        "- Stores results in memory for visualization\n",
        "- Special handling for ACO which has different function signature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run parameter sensitivity tests\n",
        "all_histories = {}  # Dictionary to store average convergence for each config\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"PARAMETER SENSITIVITY TEST: {ALGORITHM_NAME} (Discrete)\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Testing {len(CONFIGS)} configurations\")\n",
        "print(f\"Each config will run {N_RUNS} times\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for config_idx, config in enumerate(CONFIGS, 1):\n",
        "    config_label = config['label']\n",
        "    print(f\"\\n[{config_idx}/{len(CONFIGS)}] Testing: {config_label}\")\n",
        "    \n",
        "    # Extract parameters (exclude 'label' key)\n",
        "    params = {k: v for k, v in config.items() if k != 'label'}\n",
        "    \n",
        "    # Run N_RUNS times\n",
        "    config_histories = []\n",
        "    for run in range(N_RUNS):\n",
        "        print(f\"  Run {run+1}/{N_RUNS}...\", end=\" \")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Special handling for ACO (different function signature)\n",
        "        if ALGORITHM_NAME == 'ACO':\n",
        "            sol, fit, hist = ALGORITHM_FUNC(\n",
        "                knapsack_fitness, context, POP_SIZE, MAX_ITER, **params\n",
        "            )\n",
        "        else:\n",
        "            # All other algorithms (PSO, ABC, FA, CS) use _discrete functions\n",
        "            sol, fit, hist = ALGORITHM_FUNC(\n",
        "                knapsack_fitness, context, N_ITEMS, POP_SIZE, MAX_ITER, **params\n",
        "            )\n",
        "        \n",
        "        elapsed = time.time() - start_time\n",
        "        config_histories.append(hist)\n",
        "        print(f\"Fitness: {fit:.2f} ({elapsed:.2f}s)\")\n",
        "    \n",
        "    # Calculate average convergence history\n",
        "    max_len = max(len(h) for h in config_histories)\n",
        "    padded_histories = []\n",
        "    for h in config_histories:\n",
        "        if len(h) < max_len:\n",
        "            padded = list(h) + [h[-1]] * (max_len - len(h))\n",
        "        else:\n",
        "            padded = h\n",
        "        padded_histories.append(padded)\n",
        "    \n",
        "    avg_history = np.mean(np.array(padded_histories), axis=0)\n",
        "    all_histories[config_label] = avg_history\n",
        "    \n",
        "    # Calculate final statistics\n",
        "    final_fitnesses = [h[-1] for h in config_histories]\n",
        "    avg_final = np.mean(final_fitnesses)\n",
        "    std_final = np.std(final_fitnesses)\n",
        "    print(f\"  ‚Üí Avg final fitness: {avg_final:.2f} ¬± {std_final:.2f}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"ALL TESTS COMPLETED!\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Results stored for {len(all_histories)} configurations\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualization\n",
        "\n",
        "Plot all convergence curves on the same graph for easy comparison.\n",
        "\n",
        "- Each curve represents one parameter configuration\n",
        "- Curves are labeled with their configuration parameters\n",
        "- Uses linear scale on y-axis (fitness can be negative for Knapsack)\n",
        "- Color scheme automatically assigned to distinguish configurations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create color scheme for different configurations\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, len(all_histories)))\n",
        "\n",
        "# Plot all convergence curves\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "for idx, (label, history) in enumerate(all_histories.items()):\n",
        "    ax.plot(history, linewidth=2, color=colors[idx], label=label, alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Iteration', fontsize=12)\n",
        "ax.set_ylabel('Best Fitness Value', fontsize=12)\n",
        "ax.set_title(f'Parameter Sensitivity Analysis - {ALGORITHM_NAME} Discrete (N={N_ITEMS} items)', \n",
        "            fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best', fontsize=9, framealpha=0.9)\n",
        "ax.grid(True, alpha=0.3)\n",
        "# Linear scale for Knapsack (fitness can be negative)\n",
        "# Note: Lower fitness is better (minimization), but Knapsack uses negative fitness\n",
        "# So more negative = better (higher total value)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n‚úì Plotted {len(all_histories)} convergence curves\")\n",
        "print(\"üí° Compare curves to identify best parameter configuration!\")\n",
        "print(\"üí° Note: Lower fitness (more negative) = better solution (higher total value)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
